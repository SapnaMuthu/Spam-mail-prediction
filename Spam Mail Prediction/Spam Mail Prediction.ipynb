{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac40ac3e",
   "metadata": {},
   "source": [
    "Spam Mail Prediction using Machine Learning with Python:\n",
    "==\n",
    "\n",
    "Generally, a mail can be classified as:\n",
    "Spam mail: Free entry in a 2a wkly comp to win FA cup final tkts 21st May.\n",
    "Ham mail : Pls go ahead with watts. I just wanted to be sure.\n",
    "\n",
    "Workflow:\n",
    "==\n",
    "Mail Data -> Data Preproessing -> Train test split -> Logistic Regression Model (Binary Classification Problem ) -> Trained \n",
    "Regression Model (New mail is fed into the newly trained model) -> Spam or Ham (Prediction) \n",
    "\n",
    "The dataset for this project is extracted from the Google Drive link or Kaggle.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166a8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dependencies \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa8564f",
   "metadata": {},
   "source": [
    "Data Collection & Pre-processing:\n",
    "==\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a84f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      Category                                            Message\n",
      "0         ham  Go until jurong point, crazy.. Available only ...\n",
      "1         ham                      Ok lar... Joking wif u oni...\n",
      "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         ham  U dun say so early hor... U c already then say...\n",
      "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...       ...                                                ...\n",
      "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568      ham               Will ü b going to esplanade fr home?\n",
      "5569      ham  Pity, * was in mood for that. So...any other s...\n",
      "5570      ham  The guy did some bitching but I acted like i'd...\n",
      "5571      ham                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "#loading the data from the csv file to the pandas dataframe\n",
    "raw_mail_data = pd.read_csv(r\"C:\\Users\\17347\\Sapna's Projects\\Spam Mail Prediction\\mail_Data.csv\")\n",
    "print(raw_mail_data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34256105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    }
   ],
   "source": [
    "print(raw_mail_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92a67ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Category                                            Message\n",
      "0         ham  Go until jurong point, crazy.. Available only ...\n",
      "1         ham                      Ok lar... Joking wif u oni...\n",
      "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         ham  U dun say so early hor... U c already then say...\n",
      "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...       ...                                                ...\n",
      "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568      ham               Will ü b going to esplanade fr home?\n",
      "5569      ham  Pity, * was in mood for that. So...any other s...\n",
      "5570      ham  The guy did some bitching but I acted like i'd...\n",
      "5571      ham                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#replace the null values with a null string \n",
    "# mail_data = raw_mail_data.where((pd.notnull(raw_mail_data)),'')\n",
    "mail_data = raw_mail_data.fillna(' ')\n",
    "print(mail_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75904a7",
   "metadata": {},
   "source": [
    "Label Encoding:\n",
    "==\n",
    "0 -> Spam mail \n",
    "1 -> Ham/ Non - Spam mail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f58f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_data.loc[mail_data['Category'] == 'spam','Category',] = 0\n",
    "mail_data.loc[mail_data['Category'] == 'ham','Category',] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d61e310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Go until jurong point, crazy.. Available only ...\n",
      "1                           Ok lar... Joking wif u oni...\n",
      "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3       U dun say so early hor... U c already then say...\n",
      "4       Nah I don't think he goes to usf, he lives aro...\n",
      "                              ...                        \n",
      "5567    This is the 2nd time we have tried 2 contact u...\n",
      "5568                 Will ü b going to esplanade fr home?\n",
      "5569    Pity, * was in mood for that. So...any other s...\n",
      "5570    The guy did some bitching but I acted like i'd...\n",
      "5571                           Rofl. Its true to its name\n",
      "Name: Message, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#seperating the data as texts and label\n",
    "X = mail_data['Message']\n",
    "Y = mail_data['Category']\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d515367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       0\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "5567    0\n",
      "5568    1\n",
      "5569    1\n",
      "5570    1\n",
      "5571    1\n",
      "Name: Category, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2250786",
   "metadata": {},
   "source": [
    "Train Test Split:\n",
    "==\n",
    "Splitting the data set into train data and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8209d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split (X,Y, test_size = 0.2, random_state = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a88615bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n",
      "(4457,)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c05f51b",
   "metadata": {},
   "source": [
    "Feature Extraction:\n",
    "==\n",
    "Transform the text data to feature vectors(numeric values) that can be used as input to the Logistic Regression Model\n",
    "\n",
    "TfidfVectorizer looks at the data (X) and if you see all the spam mails they contain words like free, offer, discounts and so on\n",
    "and the TfidfVectorizer goes through all the words in the dataset and if the word is repeated several times it will give some values.Each word in the document is assigned with a score.\n",
    "This score is then used by our model to find out which mail are spam mail and which mail are ham mail.\n",
    "\n",
    "min_df -> if the score of a particular word is less than one then we need to ignore it , and if the score is greater than 1 we can include it so it basically means that if the word is repeated only once in that case we don't want to use those words because those words won't be that important for our prediction.\n",
    "\n",
    "stop_words -> stop words are those words that will be repeated multiple times in a dataset. stop_words can be ignored from our dataset \n",
    "\n",
    "lowercase = True -> all the letters are converted into lowercase.\n",
    "\n",
    "fit_transform -> fits all the data into the vectorizer and after that it will transform all the data into feature vectors which are nothing but the numerical values; we don't basically fit the data for the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b5a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction = TfidfVectorizer(min_df=1,stop_words='english', lowercase = 'True')\n",
    "x_train_features = feature_extraction.fit_transform(x_train)\n",
    "# we don't basically fit the data for the test data\n",
    "x_test_features = feature_extraction.transform(x_test)\n",
    "\n",
    "# convert y_train and y_test values as integers as they're considered as an object\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee71efa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4334)\t0.42941702167641554\n",
      "  (0, 3958)\t0.6161071828926097\n",
      "  (0, 6586)\t0.44333254982109394\n",
      "  (0, 6927)\t0.48935591439341625\n",
      "  (1, 2121)\t0.3573617143022146\n",
      "  (1, 1428)\t0.5869421390016223\n",
      "  (1, 6971)\t0.42812434651556874\n",
      "  (1, 3168)\t0.5869421390016223\n",
      "  (2, 5115)\t0.3408491178137899\n",
      "  (2, 7353)\t0.31988118061968496\n",
      "  (2, 3852)\t0.3408491178137899\n",
      "  (2, 4884)\t0.35749230587184955\n",
      "  (2, 5695)\t0.35749230587184955\n",
      "  (2, 806)\t0.26730249393705324\n",
      "  (2, 5894)\t0.35749230587184955\n",
      "  (2, 1876)\t0.28751725124107325\n",
      "  (2, 6878)\t0.35749230587184955\n",
      "  (3, 197)\t0.36522237107066735\n",
      "  (3, 3723)\t0.16297045459835785\n",
      "  (3, 2435)\t0.26698378141852\n",
      "  (3, 1825)\t0.26858331513730566\n",
      "  (3, 5231)\t0.2266831802864503\n",
      "  (3, 300)\t0.2915969875465198\n",
      "  (3, 7248)\t0.23571908490908416\n",
      "  (3, 5005)\t0.3169028431039865\n",
      "  :\t:\n",
      "  (4454, 2244)\t0.2526916142542512\n",
      "  (4454, 666)\t0.28653660324238944\n",
      "  (4454, 1575)\t0.20946314330145205\n",
      "  (4454, 1094)\t0.24862733340971144\n",
      "  (4454, 5068)\t0.22284357632450164\n",
      "  (4454, 311)\t0.19547195974237946\n",
      "  (4454, 4627)\t0.3831814754124698\n",
      "  (4454, 2879)\t0.28899333825056067\n",
      "  (4454, 5811)\t0.14953570764179772\n",
      "  (4454, 7248)\t0.18493430649182369\n",
      "  (4454, 7297)\t0.1741110805400093\n",
      "  (4455, 7075)\t0.6255253074975946\n",
      "  (4455, 3701)\t0.546620099025937\n",
      "  (4455, 4614)\t0.4677148905542796\n",
      "  (4455, 3084)\t0.3019392955127119\n",
      "  (4456, 3768)\t0.30090411827956587\n",
      "  (4456, 5009)\t0.6018082365591317\n",
      "  (4456, 909)\t0.26924653489772427\n",
      "  (4456, 7032)\t0.2868954144677231\n",
      "  (4456, 2509)\t0.20620887737471993\n",
      "  (4456, 380)\t0.24893867331233713\n",
      "  (4456, 7033)\t0.43304344994724825\n",
      "  (4456, 7376)\t0.20404881687716278\n",
      "  (4456, 5820)\t0.18767970267638426\n",
      "  (4456, 6575)\t0.15362974460832007\n"
     ]
    }
   ],
   "source": [
    "print(x_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240974e3",
   "metadata": {},
   "source": [
    "Training the model : Logistic Regression \n",
    "==\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2f648ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cc9a0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the Logistic Regression model with the training data \n",
    "model.fit(x_train_features,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82cdcc6",
   "metadata": {},
   "source": [
    "Evaluating the trained model:\n",
    "==\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "117bdafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on training data\n",
    "prediction_on_training_data = model.predict(x_train_features)\n",
    "accuracy_on_training_data = accuracy_score(y_train, prediction_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72d15cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.9683643706529056\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training data:',accuracy_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2aeeb4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.9524663677130045\n"
     ]
    }
   ],
   "source": [
    "#prediction on test data\n",
    "prediction_on_test_data = model.predict(x_test_features)\n",
    "accuracy_on_test_data = accuracy_score(y_test, prediction_on_test_data)\n",
    "print('Accuracy on test data:',accuracy_on_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057716d5",
   "metadata": {},
   "source": [
    "Building a Predictive System:\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd80c090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Ham mail\n"
     ]
    }
   ],
   "source": [
    "input_mail = [\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times\"]\n",
    "\n",
    "# convert text to feature vectors\n",
    "input_data_features = feature_extraction.transform(input_mail)\n",
    "\n",
    "# making prediction\n",
    "\n",
    "prediction = model.predict(input_data_features)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "if (prediction[0]==1):\n",
    "      print('Ham mail')\n",
    "\n",
    "else:\n",
    "      print('Spam mail')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
